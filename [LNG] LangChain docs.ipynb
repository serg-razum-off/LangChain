{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook is for a LCh Chat over the LCh docs\n",
    "docs were compiled from [[LCh URL]](https://python.langchain.com/en/latest/index.html#) via <br>\n",
    "```\n",
    "[URL] Get_URLs_LCh_docs.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sergey\\\\OnD_Study\\\\Neuro\\\\Langchain_Docs'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'C:\\Users\\Sergey\\OnD_Study\\Neuro\\Langchain_Docs'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [UnstructuredPDFLoader(os.path.join(path, fn)) for fn in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     31\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'C:\\\\Users\\\\Sergey/nltk_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m index \u001b[39m=\u001b[39m VectorstoreIndexCreator(\n\u001b[0;32m      2\u001b[0m     vectorstore_cls\u001b[39m=\u001b[39;49mChroma,\n\u001b[0;32m      3\u001b[0m     embedding\u001b[39m=\u001b[39;49mOpenAIEmbeddings(),\n\u001b[0;32m      4\u001b[0m     text_splitter\u001b[39m=\u001b[39;49mCharacterTextSplitter(chunk_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, chunk_overlap\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m----> 5\u001b[0m )\u001b[39m.\u001b[39;49mfrom_loaders(loaders)\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\indexes\\vectorstore.py:69\u001b[0m, in \u001b[0;36mVectorstoreIndexCreator.from_loaders\u001b[1;34m(self, loaders)\u001b[0m\n\u001b[0;32m     67\u001b[0m docs \u001b[39m=\u001b[39m []\n\u001b[0;32m     68\u001b[0m \u001b[39mfor\u001b[39;00m loader \u001b[39min\u001b[39;00m loaders:\n\u001b[1;32m---> 69\u001b[0m     docs\u001b[39m.\u001b[39mextend(loader\u001b[39m.\u001b[39;49mload())\n\u001b[0;32m     70\u001b[0m sub_docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_splitter\u001b[39m.\u001b[39msplit_documents(docs)\n\u001b[0;32m     71\u001b[0m vectorstore \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore_cls\u001b[39m.\u001b[39mfrom_documents(\n\u001b[0;32m     72\u001b[0m     sub_docs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore_kwargs\n\u001b[0;32m     73\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\document_loaders\\unstructured.py:61\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[0;32m     60\u001b[0m     \u001b[39m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m     elements \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_elements()\n\u001b[0;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39melements\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     63\u001b[0m         docs: List[Document] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\document_loaders\\pdf.py:21\u001b[0m, in \u001b[0;36mUnstructuredPDFLoader._get_elements\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_elements\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List:\n\u001b[0;32m     19\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39munstructured\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpartition\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpdf\u001b[39;00m \u001b[39mimport\u001b[39;00m partition_pdf\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m partition_pdf(filename\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munstructured_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\unstructured\\partition\\pdf.py:50\u001b[0m, in \u001b[0;36mpartition_pdf\u001b[1;34m(filename, file, url, template, token, include_page_breaks, strategy, encoding)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39m\"\"\"Parses a pdf document into a list of interpreted elements.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m    The encoding method used to decode the text input. If None, utf-8 will be used.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m exactly_one(filename\u001b[39m=\u001b[39mfilename, file\u001b[39m=\u001b[39mfile)\n\u001b[1;32m---> 50\u001b[0m \u001b[39mreturn\u001b[39;00m partition_pdf_or_image(\n\u001b[0;32m     51\u001b[0m     filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m     52\u001b[0m     file\u001b[39m=\u001b[39;49mfile,\n\u001b[0;32m     53\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m     54\u001b[0m     template\u001b[39m=\u001b[39;49mtemplate,\n\u001b[0;32m     55\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m     56\u001b[0m     include_page_breaks\u001b[39m=\u001b[39;49minclude_page_breaks,\n\u001b[0;32m     57\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[0;32m     58\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m     59\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\unstructured\\partition\\pdf.py:111\u001b[0m, in \u001b[0;36mpartition_pdf_or_image\u001b[1;34m(filename, file, url, template, token, is_image, include_page_breaks, strategy, encoding)\u001b[0m\n\u001b[0;32m    102\u001b[0m         layout_elements \u001b[39m=\u001b[39m _partition_pdf_or_image_local(\n\u001b[0;32m    103\u001b[0m             filename\u001b[39m=\u001b[39mfilename,\n\u001b[0;32m    104\u001b[0m             file\u001b[39m=\u001b[39mfile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m             include_page_breaks\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    108\u001b[0m         )\n\u001b[0;32m    110\u001b[0m \u001b[39melif\u001b[39;00m strategy \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfast\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m fallback_to_fast:\n\u001b[1;32m--> 111\u001b[0m     \u001b[39mreturn\u001b[39;00m _partition_pdf_with_pdfminer(\n\u001b[0;32m    112\u001b[0m         filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m    113\u001b[0m         file\u001b[39m=\u001b[39;49mfile,\n\u001b[0;32m    114\u001b[0m         include_page_breaks\u001b[39m=\u001b[39;49minclude_page_breaks,\n\u001b[0;32m    115\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstrategy\u001b[39m}\u001b[39;00m\u001b[39m is an invalid parsing strategy for PDFs\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\unstructured\\utils.py:40\u001b[0m, in \u001b[0;36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_deps) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     33\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFollowing dependencies are missing: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(missing_deps)\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m         \u001b[39m+\u001b[39m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m         ),\n\u001b[0;32m     39\u001b[0m     )\n\u001b[1;32m---> 40\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\unstructured\\partition\\pdf.py:204\u001b[0m, in \u001b[0;36m_partition_pdf_with_pdfminer\u001b[1;34m(filename, file, include_page_breaks, encoding)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[39mwith\u001b[39;00m open_filename(filename, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    203\u001b[0m         fp \u001b[39m=\u001b[39m cast(BinaryIO, fp)\n\u001b[1;32m--> 204\u001b[0m         elements \u001b[39m=\u001b[39m _process_pdfminer_pages(\n\u001b[0;32m    205\u001b[0m             fp\u001b[39m=\u001b[39;49mfp,\n\u001b[0;32m    206\u001b[0m             filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m    207\u001b[0m             encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    208\u001b[0m             include_page_breaks\u001b[39m=\u001b[39;49minclude_page_breaks,\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    211\u001b[0m \u001b[39melif\u001b[39;00m file:\n\u001b[0;32m    212\u001b[0m     fp \u001b[39m=\u001b[39m cast(BinaryIO, file)\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\unstructured\\partition\\pdf.py:252\u001b[0m, in \u001b[0;36m_process_pdfminer_pages\u001b[1;34m(fp, filename, encoding, include_page_breaks)\u001b[0m\n\u001b[0;32m    250\u001b[0m interpreter\u001b[39m.\u001b[39mprocess_page(page)\n\u001b[0;32m    251\u001b[0m text \u001b[39m=\u001b[39m output_string\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m--> 252\u001b[0m _elements \u001b[39m=\u001b[39m partition_text(text\u001b[39m=\u001b[39;49mtext)\n\u001b[0;32m    253\u001b[0m \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m _elements:\n\u001b[0;32m    254\u001b[0m     element\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m metadata\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\unstructured\\partition\\text.py:78\u001b[0m, in \u001b[0;36mpartition_text\u001b[1;34m(filename, file, text, encoding)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39melif\u001b[39;00m is_us_city_state_zip(ctext):\n\u001b[0;32m     77\u001b[0m     elements\u001b[39m.\u001b[39mappend(Address(text\u001b[39m=\u001b[39mctext, metadata\u001b[39m=\u001b[39mmetadata))\n\u001b[1;32m---> 78\u001b[0m \u001b[39melif\u001b[39;00m is_possible_narrative_text(ctext):\n\u001b[0;32m     79\u001b[0m     elements\u001b[39m.\u001b[39mappend(NarrativeText(text\u001b[39m=\u001b[39mctext, metadata\u001b[39m=\u001b[39mmetadata))\n\u001b[0;32m     80\u001b[0m \u001b[39melif\u001b[39;00m is_possible_title(ctext):\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\unstructured\\partition\\text_type.py:85\u001b[0m, in \u001b[0;36mis_possible_narrative_text\u001b[1;34m(text, cap_threshold, non_alpha_threshold, language, language_checks)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m under_non_alpha_ratio(text, threshold\u001b[39m=\u001b[39mnon_alpha_threshold):\n\u001b[0;32m     83\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[39mif\u001b[39;00m (sentence_count(text, \u001b[39m3\u001b[39m) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m contains_verb(text)) \u001b[39mand\u001b[39;00m language \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     86\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNot narrative. Text does not contain a verb:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\unstructured\\partition\\text_type.py:183\u001b[0m, in \u001b[0;36mcontains_verb\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mif\u001b[39;00m text\u001b[39m.\u001b[39misupper():\n\u001b[0;32m    181\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mlower()\n\u001b[1;32m--> 183\u001b[0m pos_tags \u001b[39m=\u001b[39m pos_tag(text)\n\u001b[0;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39many\u001b[39m(tag \u001b[39min\u001b[39;00m POS_VERB_TAGS \u001b[39mfor\u001b[39;00m _, tag \u001b[39min\u001b[39;00m pos_tags)\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\unstructured\\nlp\\tokenize.py:57\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences:\n\u001b[0;32m     56\u001b[0m     tokens \u001b[39m=\u001b[39m _word_tokenize(sentence)\n\u001b[1;32m---> 57\u001b[0m     parts_of_speech\u001b[39m.\u001b[39mextend(_pos_tag(tokens))\n\u001b[0;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m parts_of_speech\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\nltk\\tag\\__init__.py:165\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpos_tag\u001b[39m(tokens, tagset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, lang\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meng\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    141\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m    tag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     tagger \u001b[39m=\u001b[39m _get_tagger(lang)\n\u001b[0;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\nltk\\tag\\__init__.py:107\u001b[0m, in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    105\u001b[0m     tagger\u001b[39m.\u001b[39mload(ap_russian_model_loc)\n\u001b[0;32m    106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     tagger \u001b[39m=\u001b[39m PerceptronTagger()\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m tagger\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\nltk\\tag\\perceptron.py:167\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m load:\n\u001b[0;32m    166\u001b[0m     AP_MODEL_LOC \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[1;32m--> 167\u001b[0m         find(\u001b[39m\"\u001b[39;49m\u001b[39mtaggers/averaged_perceptron_tagger/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m PICKLE)\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload(AP_MODEL_LOC)\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\site-packages\\nltk\\data.py:522\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39m# Check each item in our path\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[39mfor\u001b[39;00m path_ \u001b[39min\u001b[39;00m paths:\n\u001b[0;32m    521\u001b[0m     \u001b[39m# Is the path item a zipfile?\u001b[39;00m\n\u001b[1;32m--> 522\u001b[0m     \u001b[39mif\u001b[39;00m path_ \u001b[39mand\u001b[39;00m (os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49misfile(path_) \u001b[39mand\u001b[39;00m path_\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m    523\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m             \u001b[39mreturn\u001b[39;00m ZipFilePathPointer(path_, resource_name)\n",
      "File \u001b[1;32mc:\\Users\\Sergey\\miniconda3\\envs\\langchain\\lib\\genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m\"\"\"Test whether a path is a regular file\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     31\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=Chroma,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    ").from_loaders(loaders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
