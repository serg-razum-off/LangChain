{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook is for a LCh Chat over the LCh docs\n",
    "docs were compiled from [[LCh URL]](https://python.langchain.com/en/latest/index.html#) via <br>\n",
    "```\n",
    "[URL] Get_URLs_LCh_docs.ipynb\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!! important:\n",
    "dectron2 prerequisites: [[SOF]](https://stackoverflow.com/questions/60631933/install-detectron2-on-windows-10)\n",
    "\n",
    "```\n",
    "Installation of detectron2 in Windows is somehow tricky. I struggled a whole week to make it work <...>\n",
    "\n",
    "    conda install -c anaconda cudatoolkit=11.3\n",
    "    conda install -c anaconda cudnn\n",
    "    conda install -c anaconda pywin32\n",
    "```\n",
    "conda install -c pytorch pytorch  <br>\n",
    "conda install -c pytorch torchvision <br>\n",
    "pip install \"git+https://github.com/facebookresearch/detectron2.git@v0.3\" <br>\n",
    "conda install -c conda-forge poppler\n",
    "\n",
    "for tesseract Err read [[SOF]](https://stackoverflow.com/questions/50951955/pytesseract-tesseractnotfound-error-tesseract-is-not-installed-or-its-not-i) <br>\n",
    "--> note that tesseract after win-installing should be added to PATH <br>\n",
    "--> pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.ex\n",
    "\n",
    "For having Chroma.db persisted, see this [[GH Thread]](https://github.com/hwchase17/langchain/issues/2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= PDF folder =========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sergey\\\\OnD_Study\\\\Neuro\\\\Langchain_Docs\\\\Chroma_Dir\\\\pdfs'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'C:\\Users\\Sergey\\OnD_Study\\Neuro\\Langchain_Docs\\Chroma_Dir\\pdfs'\n",
    "print('='*25 + \" PDF folder \" + '='*25)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> list of loaders comprehended: [4]\n"
     ]
    }
   ],
   "source": [
    "loaders = [UnstructuredPDFLoader(os.path.join(path, fn)) for fn in os.listdir(path)]\n",
    "\n",
    "print(f\">> list of loaders comprehended: [{len(loaders)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:58<00:00, 14.54s/it]\n",
      "Using embedded DuckDB with persistence: data will be stored in: C:\\Users\\Sergey\\OnD_Study\\Neuro\\Langchain_Docs\\Chroma_Dir\\db\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "db_dir = r\"C:\\Users\\Sergey\\OnD_Study\\Neuro\\Langchain_Docs\\Chroma_Dir\\db\"\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=Chroma,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=50),\n",
    "    vectorstore_kwargs={\"persist_directory\": db_dir}\n",
    ").from_loaders(tqdm(loaders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__class_vars__',\n",
       " '__init_subclass__',\n",
       " '__subclasshook__',\n",
       " '_decompose_class']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = \"kwa ss\".split(\" \")\n",
    "meth_list = [meth for meth in dir(VectorstoreIndexCreator) if any(sear in meth for sear in search)]\n",
    "\n",
    "meth_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
